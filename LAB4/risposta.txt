Linpeng Zhang 1162114
Michele Roverato 1143030
Martino Echerle 1206691

Nota:
Sono stati sviluppati due versioni del calcolo del centro di un cluster:
- quello visto a lezione, che consiste nella media aritmetica delle coordinate di ciascuna città nel cluster;
- una variante che consiste nella media delle coordinate pesata con la popolazione di ciascuna città nel cluster.
La motivazione è che per il calcolo della distorsione si pesano le distanze a seconda della popolazione. È chiaro che, tenerne conto nell'algoritmo di clustering, può ridurre significativamente la distorsione. 
Le immagini, quindi, sono state suddivise in due cartelle:
classic_algorithm_img e population_weight_algorithm_img

Domanda 1
Immagine H_FULL.png

Domanda 2
Immagine K_FULL.png

Domanda 3
Il tempo di K-means dipende dal ciclo esterno principale, che viene compiuto q volte. Al suo interno si ha:
- la creazione dei k cluster che richiede tempo O(k)
- il calcolo del centroide più vicino ad ogni punto, che richiede tempo O(nk)
- il ricalcolo dei centroidi che richiede tempo O(n)
Quindi K-means richiede tempo O(q(k+nk+n))=O(qnk)
-------------------------------------
Il tempo di HierarchicalClustering, supponendo che si utilizzi l'algoritmo FastClosestPair, è governato dal ciclo while effettuato al più O(n-k) volte. Al suo interno si ha:
- la chiamata a FastClosestPair che richiede tempo O(nlogn)
- Unione e differenza dei cluster che richiedono tempo certamente al più O(n), e che quindi è irrilevante a fini asintotici (FastClosestPair richiede più tempo)
Quindi HierarchicalClustering richiede tempo O((n-k)(nlogn+n)=O((n-k)(nlogn))
--------------------------------------
Nell'ipotesi che:
- il numero di cluster di output sia piccolo, ovvero k=O(1);
- il numero di iterazioni di K-Means sia piccolo, ovvero q=O(1);
si ha che:
K-means richiede tempo O(qnk)=O(n)
HierarchicalClustering richiede tempo O((n-k)(nlogn))=O(n^2logn)
da cui è evidente che K-means è più prestante.

Domanda 4
Immagine H_212.png

Domanda 5
Immagine K_212.png

Domanda 6
Con l'algoritmo visto a lezione
Distortion for hierchical clustering: 1.967522133749596e11
Distortion for kmeans clustering: 9,538276536533682e10

Con calcolo del centro pesato in base alla popolazione
Distortion for hierchical clustering: 6.064330484847967e10
Distortion for kmeans clustering: 6.610124590745788e10

Notiamo che la "variante" riduce sensibilmente la distorsione.

Domanda 7
In H_212.png abbiamo un unico cluster nella costa occidentale. In K_212.png ce ne sono tre. Questa differenza è dovuta al fatto che k-means sceglie inizialmente i k centroidi scegliendo le contee più popolose. In corrispondenza di quella fascia vi sono almeno 3 contee tra le k più popolose, tra cui menzioniamo anche la presenza di grandi città come San Francisco, Las Vegas, San Diego, Los Angeles,...
Si formeranno quindi questi 3 cluster che certamente contengono la contea che ha "inizializzato" il centroide, in quanto si trova inizialmente a distanza nulla da questo.
Utilizzando l'algoritmo visto a lezione, la distorsione di questi cluster con 1 città, con k-means, è nulla; mentre con HierarchicalClustering si riuniscono città molto popolose, motivo per cui la distorsione aumenta in maniera significativa, risultando peggiore di k-means.
Utilizzando la variante, si forma comunque un unico cluster nella parte occidentale. Il calcolo del centro, tuttavia, è ora influenzato dalla popolazione, ridicendo significativamente la distorsione.

Domanda 8
Utilizzando l'algoritmo visto a lezione, risulta preferibile K-Means perché il clustering gerarchico ignora la popolazione, che invece risulta determinante nel calcolo della distorsione.
Utilizzando la variante sceglierei il clustering gerarchico perché non è influenzato dalla scelta dei centroidi iniziali, e soprattutto perché si può calcolare la distorsione man mano che l'algoritmo prosegue, ed eventualmente fermarsi prima.

Domanda 9
Immagini distortion_212.png, distortion_562.png, distortion_1041.png

Domanda 10
Non c'è un algoritmo migliore in tutti i casi. Infatti, con entrambi gli algoritmi, le distorsioni sembrano alternarsi a seconda del numero di cluster. Comunque l'algoritmo che utilizza il centro pesato in base alla popolazione ha distorsioni più basse, e la differenza è particolarmente evidente in HierarchicalClustering.